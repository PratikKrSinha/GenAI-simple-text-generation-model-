{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**An N-Gram model is a statistical language model that predicts the next word based on the previous N‚àí1 words**.\n",
        "**bold text****bold text**\n",
        "For example:\n",
        "\n",
        "Bigram (N=2) ‚Üí uses 1 previous word\n",
        "\n",
        "Trigram (N=3) ‚Üí uses 2 previous words\n",
        "\n",
        "It learns word patterns from a given dataset and generates new text by selecting the most likely next word.\n",
        "\n",
        "It is simple, fast, and helps understand the basics of language modeling before moving to neural networks."
      ],
      "metadata": {
        "id": "yGFaWYehePSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# N-GRAM TEXT GENERATION MODEL\n",
        "# ===============================\n",
        "\n",
        "import re\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Load Dataset\n",
        "# -------------------------------\n",
        "\n",
        "text = \"\"\"\n",
        "artificial intelligence is transforming modern society.\n",
        "it is used in healthcare finance education and transportation.\n",
        "machine learning allows systems to improve automatically with experience.\n",
        "data plays a critical role in training intelligent systems.\n",
        "large datasets help models learn complex patterns.\n",
        "deep learning uses multi layer neural networks.\n",
        "neural networks are inspired by biological neurons.\n",
        "each neuron processes input and produces an output.\n",
        "training a neural network requires optimization techniques.\n",
        "gradient descent minimizes the loss function.\n",
        "\"\"\"\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Preprocessing\n",
        "# -------------------------------\n",
        "\n",
        "text = text.lower()\n",
        "text = re.sub(r'[^a-z\\s]', '', text)\n",
        "words = text.split()\n",
        "\n",
        "print(\"Total Words:\", len(words))\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Build N-Gram Model (Trigram)\n",
        "# -------------------------------\n",
        "\n",
        "def build_ngram_model(words, n):\n",
        "    model = defaultdict(list)\n",
        "\n",
        "    for i in range(len(words) - n + 1):\n",
        "        context = tuple(words[i:i+n-1])\n",
        "        target = words[i+n-1]\n",
        "        model[context].append(target)\n",
        "\n",
        "    return model\n",
        "\n",
        "n = 3  # Change to 2 for Bigram, 4 for 4-gram\n",
        "ngram_model = build_ngram_model(words, n)\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Text Generation Function\n",
        "# -------------------------------\n",
        "\n",
        "def generate_text(model, seed_text, n, num_words=20):\n",
        "    seed_words = seed_text.lower().split()\n",
        "\n",
        "    for _ in range(num_words):\n",
        "        context = tuple(seed_words[-(n-1):])\n",
        "\n",
        "        if context in model:\n",
        "            next_word = random.choice(model[context])\n",
        "            seed_words.append(next_word)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return \" \".join(seed_words)\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Generate Text\n",
        "# -------------------------------\n",
        "\n",
        "seed = \"artificial intelligence\"\n",
        "generated_text = generate_text(ngram_model, seed, n, num_words=20)\n",
        "\n",
        "print(\"\\nGenerated Text:\\n\")\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbeNcm-PeVjK",
        "outputId": "f178b06b-19bb-4eeb-e08a-2e2e91b64292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Words: 75\n",
            "\n",
            "Generated Text:\n",
            "\n",
            "artificial intelligence is transforming modern society it is used in healthcare finance education and transportation machine learning allows systems to improve automatically\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ Limitations\n",
        "\n",
        "‚ùå Cannot capture long-term dependencies\n",
        "\n",
        "‚ùå Suffers from data sparsity\n",
        "\n",
        "‚ùå Memory requirement increases with larger N\n",
        "\n",
        "‚ùå Cannot generalize well to unseen text\n",
        "\n",
        "‚ùå Mostly memorizes patterns instead of understanding\n",
        "\n",
        "Because of these limitations, we move to RNN/LSTM models next."
      ],
      "metadata": {
        "id": "LzrKDxNUitEd"
      }
    }
  ]
}